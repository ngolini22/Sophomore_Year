http://www.cs.dartmouth.edu/%7Ecampbell/cs50/lab4.html
3
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title></title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="lab4.tex"> 
<meta name="date" content="2015-05-04 14:19:00"> 
<link rel="stylesheet" type="text/css" href="lab4.css"> 
</head><body 
>
<h1 class="likepartHead"><a 
 id="x1-1000"></a>CS 50 Software Design and Implementation</h1>
<h1 class="likepartHead"><a 
 id="x1-2000"></a>Lab4</h1>
<h1 class="likepartHead"><a 
 id="x1-3000"></a>TinySearch Engine: Crawler Lab</h1>
<!--l. 19--><p class="noindent" >Lab4 starts a series of three assignments that will build the TinySearch Engine. This lab will design,
implement and test the crawler module.
<!--l. 21--><p class="noindent" ><span 
class="cmbx-10">Tarball of files you need</span>
<!--l. 23--><p class="noindent" >Here is tarball of all the files you need for this lab rather than copying them over from my webpage. untar
the file:<br 
class="newline" />
<!--l. 25--><p class="noindent" >tar xvfz lab4handout.tar.gz<br 
class="newline" />
<!--l. 27--><p class="noindent" ><a 
href="http://www.cs.dartmouth.edu/~campbell/cs50/lab4handout.tar.gz" > lab4handout.tar.gz </a>.
<!--l. 29--><p class="noindent" ><span 
class="cmbx-10">The design of the crawler will be discussed in class as a collective design. We will develop</span>
<span 
class="cmbx-10">the design and implementation in class. All students will implement the same DESIGN</span>
<span 
class="cmbx-10">SPEC developed in class</span>.
<!--l. 31--><p class="noindent" >This is a challenging assignment. It includes data structures of link lists and a hash table and hash
function. We will discuss both of these data structures in class.
<!--l. 33--><p class="noindent" >This lab will cover many aspects of the C language discussed in class: structures, pointers, string
processing, malloc/free, file operations and management, and interacting with the shell to execute wget
via the system call (which you used in the last lab).
<!--l. 35--><p class="noindent" >Importantly, for this lab you will use multiple files. Single functions or groups of related functions will go
in their own .c file (e.g., crawler.c, list.c, html.c). You will also write header files for this lab which be
included in the your various .c files.
<!--l. 37--><p class="noindent" >We also use the GNU make command to help manage and compile these multiple files. Here is a snippet
from man:
<div 
class="colorbox" id="colorbox1"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">NAME</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;make</span><span 
class="cmtt-10">&#x00A0;-</span><span 
class="cmtt-10">&#x00A0;GNU</span><span 
class="cmtt-10">&#x00A0;make</span><span 
class="cmtt-10">&#x00A0;utility</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;maintain</span><span 
class="cmtt-10">&#x00A0;groups</span><span 
class="cmtt-10">&#x00A0;of</span><span 
class="cmtt-10">&#x00A0;programs</span><br /><br /><span 
class="cmtt-10">SYNOPSIS</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;make</span><span 
class="cmtt-10">&#x00A0;[</span><span 
class="cmtt-10">&#x00A0;-f</span><span 
class="cmtt-10">&#x00A0;makefile</span><span 
class="cmtt-10">&#x00A0;]</span><span 
class="cmtt-10">&#x00A0;[</span><span 
class="cmtt-10">&#x00A0;option</span><span 
class="cmtt-10">&#x00A0;]</span><span 
class="cmtt-10">&#x00A0;...</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;target</span><span 
class="cmtt-10">&#x00A0;...</span><br /><br /><span 
class="cmtt-10">DESCRIPTION</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;purpose</span><span 
class="cmtt-10">&#x00A0;of</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;make</span><span 
class="cmtt-10">&#x00A0;utility</span><span 
class="cmtt-10">&#x00A0;is</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;determine</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;automatically</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;which</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;pieces</span><span 
class="cmtt-10">&#x00A0;of</span><span 
class="cmtt-10">&#x00A0;a</span><span 
class="cmtt-10">&#x00A0;large</span><span 
class="cmtt-10">&#x00A0;program</span><span 
class="cmtt-10">&#x00A0;need</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;be</span><span 
class="cmtt-10">&#x00A0;recompiled,</span><span 
class="cmtt-10">&#x00A0;and</span><span 
class="cmtt-10">&#x00A0;issue</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;commands</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;recompile</span><span 
class="cmtt-10">&#x00A0;them.</span><br /><br /></div></div>
<!--l. 61--><p class="noindent" ><span 
class="cmbx-10">Grading: </span><a 
href="http://www.cs.dartmouth.edu/~campbell/cs50/rubric4.html" > Grading rubric for lab</a>.
<!--l. 64--><p class="noindent" ><span 
class="cmbx-10">Submitting assignment</span>:
<!--l. 66--><p class="noindent" >Use svn as normal.
                                                                                  
                                                                                  
<!--l. 68--><p class="noindent" >Please make sure that the lab4 directory contains a simple text file, named README, describing anything
&#8220;unusual&#8221; about how your solutions should be located, executed, and considered.
<!--l. 70--><p class="noindent" ><span 
class="cmbx-10">Coding style</span>: Please put comments in your programs to help increase its understanding. Include a
header in each C file including the file name; brief description of the program; inputs; and outputs. It
is important you write C programs <span 
class="cmbx-10">defensively</span>; that is, you need to check the program&#8217;s
input and provide appropriate warning or error messages back to the user in terms of the
program usage. If you call functions from your code make sure you check the return status
(if available) and print out meaningful error messages and take suitable action. See testing
below.
<!--l. 72--><p class="noindent" ><span 
class="cmbx-10">Multiple files and make</span>. Your directory will include a make file that will be used to do a build of your
system. We will discuss the make utility in class this week. As part of grading we will do a build using the
make command. There should be no warnings from the compiler.
<!--l. 74--><p class="noindent" ><span 
class="cmbx-10">Writing a bash test script to automatically test your crawler program</span>. You will also be asked to
write a test.sh that calls your crawler program multiple times with different parameters to check the
operation of the program. For example, how does your program deals with various input some of
which will be erroneous (e.g., bad URL, depth to large, etc.). Writing a test.sh script has the
benefit that if you have changed your code you can quickly rerun the new build (output of
the make) against your test script as a sanity check that nothing has been broken. While we
will discuss unit testing in more detail for Lab5 we will start with Lab4 to get students to
write simple bash shells (these are tools that are specific to testing the program) to test their
code. Note, we expect that the test.sh script and the log from the tests will be included in the
tarball. Call the test script <span 
class="cmti-10">crawler</span><span 
class="cmti-10">_test.sh </span>and the log of what the test prints out should
be directed to a file called <span 
class="cmti-10">crawler</span><span 
class="cmti-10">_testlog.&#8216;date&#8216; </span>(i.e., crawler_testlog.Wed Jan 30 02:17:20
EST 2008). Again, these two files must be included in your tarball. As part of your grade we
will run you script against your code and look at the new log produced. Please make sure
that your test script writes out the name of the test, expected results, and what the system
outputs.
<!--l. 76--><p class="noindent" ><span 
class="cmbx-10">Testing at depth 3</span>. You should incrementally test your crawler at depth 1, 2 and 3 to build confidence
in your code. Note, that the <span 
class="cmti-10">final submitted code must work at depth 3</span>. It will be tested at depth 3 as part
of grading.
<!--l. 78--><p class="noindent" ><span 
class="cmbx-10">We will not grade labs that segfault</span>. You would not buy a product that crashed. So please do not
submit a lab that has segfaults. We will not grade it. You will have to fix the segfaults and resubmit
the lab. There will be penalties. This is in fairness to students that submited labs without
segfaults.
<!--l. 80--><p class="noindent" >____________________________________________________________________________
<h3 class="likesectionHead"><a 
 id="x1-4000"></a>Crawler Requirements</h3>
<!--l. 84--><p class="noindent" >Design, implement, and test (but not exhaustively at this stage) a standalone crawler. The design of
crawler will be done in class. In the next lecture we will start to develop a DESIGN SPEC for the
crawler module. We will also develop an IMPLEMENTATION SPEC. Based on these two specs
you will have a blueprint of the system to develop your own implementation that you can
                                                                                  
                                                                                  
test.
<!--l. 86--><p class="noindent" >The crawler is a standalone program that crawls the web and retrieves webpage starting with
a seed URL. It parses the seed webpage extracts any embedded URLs that are tagged as
discussed above and retrieves those pages, and so on. Once the crawler has completed at least one
complete crawling cycle (i.e., it has visited a target number of Web pages which is defined by a
<span 
class="cmti-10">depth </span>parameter on the crawler command line) then the crawler process will complete its
operation.
<!--l. 88--><p class="noindent" >The crawler REQUIREMENTS are as follows. The crawler SHALL (a term here that means
requirement):
     <ul class="itemize1">
     <li class="itemize">receives a SEED_URL as input - considered as the initial URL;
     </li>
     <li class="itemize">only needs one good (i.e., valid/page found) URL to start the crawler process;
     </li>
     <li class="itemize">retrieves the seed page from the Web using the SEED_URL;
     </li>
     <li class="itemize">uses wget to transfer webpages to the TARGET_DIRECTORY;
     </li>
     <li class="itemize">parses the embedded URL links inside the seed page;
     </li>
     <li class="itemize">stores theses URL links in the <span class="obeylines-h"><span class="verb"><span 
class="cmtt-10">URLsList</span></span></span> The URL is only added to the URL List iff it is not
     already present in the list. Each element of this list is associated with a boolean flag <span class="obeylines-h"><span class="verb"><span 
class="cmtt-10">visited</span></span></span>
     that is initialized to false;
     </li>
     <li class="itemize">saves the seed webpage as a unique document ID starting at one and incrementing by one;
     </li>
     <li class="itemize">saves the SEED_URL and current depth in the file too. The SEED_URL is put on the first
     line and the depth on the second line. The HTML follows.
     </li>
     <li class="itemize">The crawler sets the seed URL as visited;
     </li>
     <li class="itemize">The crawler repeats the <span 
class="cmbx-10">crawl cycle </span>getting a new URL for a webpage not visited (not
     the seed because that has been visited). The crawler gets a new address from the <span class="obeylines-h"><span class="verb"><span 
class="cmtt-10">URLsList</span></span></span>,
     retrieves the page, parses for new URL links inside page; stores these new URL links in the
     URL list if not already in the <span class="obeylines-h"><span class="verb"><span 
class="cmtt-10">URLsList</span></span></span>; and sets the current URL as visited in the <span class="obeylines-h"><span class="verb"><span 
class="cmtt-10">URLsList</span></span></span>
     (i.e., <span class="obeylines-h"><span class="verb"><span 
class="cmtt-10">visited=true</span></span></span>).</li></ul>
<!--l. 103--><p class="noindent" >The TinySearch architecture is shown in Figure 1. Observe the crawled webpages saved with unique
document ID as the file name. The URL and the current depth of the search is stored in each
                                                                                  
                                                                                  
file.
<!--l. 105--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                  
                                                                                  
<a 
 id="x1-40011"></a>
                                                                                  
                                                                                  
<!--l. 106--><p class="noindent" ><img 
src="lab40x.png" alt="PIC" class="graphics" width="578.15999pt" height="483.11813pt" ><!--tex4ht:graphics  
name="lab40x.png" src="tinysearch.eps"  
-->
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">Crawler: webpages are saved as file with unique document IDs; the URL and depth are
save in first two lines.</span></div><!--tex4ht:label?: x1-40011 -->
                                                                                  
                                                                                  
<!--l. 109--><p class="noindent" ></div><hr class="endfigure">
<!--l. 111--><p class="noindent" ><span 
class="cmbx-10">When does it complete</span>. The crawler cycle completes when either all the URLs in the URL list
are visited or an external stop command is issued. Note, the crawler stops retrieving new
webpages once its as reached the depth of the depth parameter. For example, if the depth = 1
then only the seed page is retrieved and the pages of the URLs embedded in the seed page. If
the depth = 2 then all the pages pointed to by the pages with embedded URL in the seed
page are retrieved. The depth parameter tunes the number of pages that the crawler will
retrieve.
<!--l. 113--><p class="noindent" ><span 
class="cmbx-10">Need to sleep </span>Because webservers DO NOT like crawlers (think about why) they will block your
crawler based on its address. THIS is a real problem. Why? Imagine you launch your spiffy
TinySearch crawler and crawl the New York Times webpage continuously and fast. The New York
Times server will try and serve your pages as fast as it can. Imagine 100s of crawlers launched
against the server? Yes, it would spend an increasing amount of time serving crawlers and not
customers.
<!--l. 115--><p class="noindent" >But, wait. What would the New York Times do if it detects you crawling heavily from a domain
dartmouth.edu? It would likely block the domain, i.e., the complete dartmouth community! What would
that mean? Probably, Jim Kim wouldn&#8217;t be able to read his New York Times and I&#8217;m toast. So what
should we do? Well let&#8217;s try and not look like a crawler to the New York Times website. Let&#8217;s introduce
a delay. Just like spy - recall? - lets sleep for a period INTERVAL_PER_FETCH. Sneaky
hey.
<h3 class="likesectionHead"><a 
 id="x1-5000"></a>Command-line execution</h3>
<!--l. 119--><p class="noindent" >The crawler command takes the following input:
<div 
class="colorbox" id="colorbox2"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">./crawler</span><span 
class="cmtt-10">&#x00A0;[SEED_URL]</span><span 
class="cmtt-10">&#x00A0;[TARGET_DIRECTORY</span><span 
class="cmtt-10">&#x00A0;WHERE</span><span 
class="cmtt-10">&#x00A0;TO</span><span 
class="cmtt-10">&#x00A0;PUT</span><span 
class="cmtt-10">&#x00A0;THE</span><span 
class="cmtt-10">&#x00A0;DATA]</span><span 
class="cmtt-10">&#x00A0;[CRAWLING_DEPTH]</span><br /><br /><span 
class="cmtt-10">Example</span><span 
class="cmtt-10">&#x00A0;command</span><span 
class="cmtt-10">&#x00A0;input</span><br /><br /><span 
class="cmtt-10">crawler</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu</span><span 
class="cmtt-10">&#x00A0;./data/</span><span 
class="cmtt-10">&#x00A0;2</span><br /><br /><span 
class="cmtt-10">[SEED_URL]</span><br /><span 
class="cmtt-10">Requirement:</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;URL</span><span 
class="cmtt-10">&#x00A0;must</span><span 
class="cmtt-10">&#x00A0;be</span><span 
class="cmtt-10">&#x00A0;valid.</span><br /><span 
class="cmtt-10">Usage:</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;crawler</span><span 
class="cmtt-10">&#x00A0;needs</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;inform</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;user</span><span 
class="cmtt-10">&#x00A0;if</span><span 
class="cmtt-10">&#x00A0;URL</span><span 
class="cmtt-10">&#x00A0;is</span><span 
class="cmtt-10">&#x00A0;not</span><span 
class="cmtt-10">&#x00A0;found</span><br /><br /><span 
class="cmtt-10">[TARGET_DIRECTORY]</span><br /><span 
class="cmtt-10">Requirement:</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;directory</span><span 
class="cmtt-10">&#x00A0;must</span><span 
class="cmtt-10">&#x00A0;exist</span><span 
class="cmtt-10">&#x00A0;and</span><span 
class="cmtt-10">&#x00A0;be</span><span 
class="cmtt-10">&#x00A0;already</span><span 
class="cmtt-10">&#x00A0;created</span><span 
class="cmtt-10">&#x00A0;by</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;user.</span><br /><span 
class="cmtt-10">Usage:</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;crawler</span><span 
class="cmtt-10">&#x00A0;needs</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;inform</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;user</span><span 
class="cmtt-10">&#x00A0;if</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;directory</span><span 
class="cmtt-10">&#x00A0;can</span><span 
class="cmtt-10">&#x00A0;not</span><span 
class="cmtt-10">&#x00A0;be</span><span 
class="cmtt-10">&#x00A0;found</span><br /><br /><span 
class="cmtt-10">[CRAWLING_DEPTH]</span><br /><span 
class="cmtt-10">Requirement:</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;crawl</span><span 
class="cmtt-10">&#x00A0;depth</span><span 
class="cmtt-10">&#x00A0;cannot</span><span 
class="cmtt-10">&#x00A0;exceed</span><span 
class="cmtt-10">&#x00A0;4</span><br /><span 
class="cmtt-10">Usage:</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;crawler</span><span 
class="cmtt-10">&#x00A0;needs</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;inform</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;user</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;user</span><span 
class="cmtt-10">&#x00A0;exceeds</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;maximum</span><span 
class="cmtt-10">&#x00A0;depth</span><br /><br /><span 
class="cmtt-10">For</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;example</span><span 
class="cmtt-10">&#x00A0;command</span><span 
class="cmtt-10">&#x00A0;line:</span><br /><br /><span 
class="cmtt-10">crawler</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu</span><span 
class="cmtt-10">&#x00A0;./data/</span><span 
class="cmtt-10">&#x00A0;2</span><br /><br /><span 
class="cmtt-10">[SEED_URL]</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu</span><br /><span 
class="cmtt-10">[TARGET_DIRECTORY]</span><span 
class="cmtt-10">&#x00A0;./data/</span><br /><span 
class="cmtt-10">[CRAWLING_DEPTH]</span><span 
class="cmtt-10">&#x00A0;2</span><br /><br /></div></div>
<!--l. 156--><p class="noindent" >Tip: You need to determine if the TARGET_DIRECTORY is a valid directory. You can use the <a 
href="http://linux.about.com/library/cmd/blcmdl2_stat.htm" >stat()
function and macros </a>to help here.
<!--l. 159--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-6000"></a>Crawler output</h3>
<!--l. 161--><p class="noindent" >The output of your crawler program should be:
<div 
class="colorbox" id="colorbox3"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">For</span><span 
class="cmtt-10">&#x00A0;each</span><span 
class="cmtt-10">&#x00A0;webpage</span><span 
class="cmtt-10">&#x00A0;crawled</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;crawler</span><span 
class="cmtt-10">&#x00A0;program</span><span 
class="cmtt-10">&#x00A0;will</span><span 
class="cmtt-10">&#x00A0;create</span><span 
class="cmtt-10">&#x00A0;a</span><span 
class="cmtt-10">&#x00A0;file</span><span 
class="cmtt-10">&#x00A0;in</span><span 
class="cmtt-10">&#x00A0;the</span><br /><span 
class="cmtt-10">[TARGET_DIRECTORY].</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;name</span><span 
class="cmtt-10">&#x00A0;of</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;file</span><span 
class="cmtt-10">&#x00A0;will</span><span 
class="cmtt-10">&#x00A0;start</span><span 
class="cmtt-10">&#x00A0;a</span><span 
class="cmtt-10">&#x00A0;1</span><span 
class="cmtt-10">&#x00A0;for</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;[SEED_URL]</span><br /><span 
class="cmtt-10">and</span><span 
class="cmtt-10">&#x00A0;be</span><span 
class="cmtt-10">&#x00A0;incremented</span><span 
class="cmtt-10">&#x00A0;for</span><span 
class="cmtt-10">&#x00A0;each</span><span 
class="cmtt-10">&#x00A0;subsequent</span><span 
class="cmtt-10">&#x00A0;HTML</span><span 
class="cmtt-10">&#x00A0;webpage</span><span 
class="cmtt-10">&#x00A0;crawled.</span><br /><br /><span 
class="cmtt-10">Each</span><span 
class="cmtt-10">&#x00A0;file</span><span 
class="cmtt-10">&#x00A0;(e.g.,</span><span 
class="cmtt-10">&#x00A0;10)</span><span 
class="cmtt-10">&#x00A0;will</span><span 
class="cmtt-10">&#x00A0;include</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;URL</span><span 
class="cmtt-10">&#x00A0;associated</span><span 
class="cmtt-10">&#x00A0;with</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;saved</span><span 
class="cmtt-10">&#x00A0;webpage</span><span 
class="cmtt-10">&#x00A0;and</span><span 
class="cmtt-10">&#x00A0;the</span><br /><span 
class="cmtt-10">current</span><span 
class="cmtt-10">&#x00A0;depth</span><span 
class="cmtt-10">&#x00A0;of</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;search</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;(e.g.,</span><span 
class="cmtt-10">&#x00A0;1,</span><span 
class="cmtt-10">&#x00A0;2,</span><span 
class="cmtt-10">&#x00A0;..</span><span 
class="cmtt-10">&#x00A0;N)</span><span 
class="cmtt-10">&#x00A0;in</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;file.</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;URL</span><span 
class="cmtt-10">&#x00A0;will</span><span 
class="cmtt-10">&#x00A0;be</span><span 
class="cmtt-10">&#x00A0;on</span><span 
class="cmtt-10">&#x00A0;the</span><br /><span 
class="cmtt-10">first</span><span 
class="cmtt-10">&#x00A0;line</span><span 
class="cmtt-10">&#x00A0;of</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;file</span><span 
class="cmtt-10">&#x00A0;and</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;depth</span><span 
class="cmtt-10">&#x00A0;on</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;second</span><span 
class="cmtt-10">&#x00A0;line.</span><span 
class="cmtt-10">&#x00A0;The</span><span 
class="cmtt-10">&#x00A0;HTML</span><span 
class="cmtt-10">&#x00A0;for</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;webpage</span><br /><span 
class="cmtt-10">will</span><span 
class="cmtt-10">&#x00A0;start</span><span 
class="cmtt-10">&#x00A0;on</span><span 
class="cmtt-10">&#x00A0;the</span><span 
class="cmtt-10">&#x00A0;third</span><span 
class="cmtt-10">&#x00A0;line.</span><br /><br /></div></div>
<!--l. 181--><p class="noindent" >Once the crawler starts to run it gets wget to download the SEED_URL then it starts to process each
webpage hunting for new URLs. <span 
class="cmbx-10">A parser function (which we will provide to you) runs through</span>
<span 
class="cmbx-10">the stored webpage looking for URLs</span>. These are stored in a URLList for later processing. The
crawler must remove duplicate URLs that it finds (or better it marks that it has visited a webpage (URL)
and does not visit again even if it finds the same URL again. There are also conditions of stale URLs that
                                                                                  
                                                                                  
give &#8220;Page Not Found&#8221;.
<!--l. 184--><p class="noindent" >Below is a snipped when the program starts to crawl the CS webserver to a depth of 2. Meaning it
will attempt to visit all URLs in the main CS webpage and then all URLs in those pages.
The crawler prints status information as it goes along (this could be used in debug mode to
observe the operation of the crawler as it moves through its workload). Note, you should use a
LOGSTAUS macro that can be set when compiling to switch these status print outs on or off.
In addition, you should be able to write the output to a logfile to look at later should you
wish.
<!--l. 186--><p class="noindent" >In the snippet, the program get the SEED_URL page then prints out all the URLs it finds and
then crawls http://www.cs.dartmouth.edu/index.php next. PHP is a scripting language that
produces HTML - .php provides a valid webpage just like .html. In the snippet it only get two
webpages.
<div 
class="colorbox" id="colorbox4"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">atc@dhcp-212-163</span><span 
class="cmtt-10">&#x00A0;crawler]</span><span 
class="cmtt-10">&#x00A0;crawler</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu</span><span 
class="cmtt-10">&#x00A0;./data/</span><span 
class="cmtt-10">&#x00A0;2</span><br /><span 
class="cmtt-10">Crawler]Crawlingwww.cs.dartmouth.edu</span><br /><span 
class="cmtt-10">--02:36:10--</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;http://www.cs.dartmouth.edu/</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;=&#x003E;</span><span 
class="cmtt-10">&#x00A0;&#8216;temp&#8217;</span><br /><span 
class="cmtt-10">Resolving</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu...</span><span 
class="cmtt-10">&#x00A0;done.</span><br /><span 
class="cmtt-10">Connecting</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu[129.170.213.101]:80...</span><span 
class="cmtt-10">&#x00A0;connected.</span><br /><span 
class="cmtt-10">HTTP</span><span 
class="cmtt-10">&#x00A0;request</span><span 
class="cmtt-10">&#x00A0;sent,</span><span 
class="cmtt-10">&#x00A0;awaiting</span><span 
class="cmtt-10">&#x00A0;response...</span><span 
class="cmtt-10">&#x00A0;200</span><span 
class="cmtt-10">&#x00A0;OK</span><br /><span 
class="cmtt-10">Length:</span><span 
class="cmtt-10">&#x00A0;7,679</span><span 
class="cmtt-10">&#x00A0;[text/html]</span><br /><br /><span 
class="cmtt-10">100%[===================================================&#x003E;]</span><span 
class="cmtt-10">&#x00A0;7,679</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;7.32M/s</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;ETA</span><span 
class="cmtt-10">&#x00A0;00:00</span><br /><br /><span 
class="cmtt-10">02:36:10</span><span 
class="cmtt-10">&#x00A0;(7.32</span><span 
class="cmtt-10">&#x00A0;MB/s)</span><span 
class="cmtt-10">&#x00A0;-</span><span 
class="cmtt-10">&#x00A0;&#8216;temp&#8217;</span><span 
class="cmtt-10">&#x00A0;saved</span><span 
class="cmtt-10">&#x00A0;[7679/7679]</span><br /><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/index.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/about.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/news.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/people.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/jobs.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/contact.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/internal/</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/research.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/seminar.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/books.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/reports</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/ug.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/gr.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/ug_courses.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/gr_courses.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/robotcamp</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.dartmouth.edu/apply</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/admit_ms.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/admit_phd.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/~mdphd</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/gr_life.php</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/~sws</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.ams.org/bull</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/~afra</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.ams.org/bull/2008-45-01/home.html</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/~farid</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/farid/press/todayshow07.html</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:www.cs.dartmouth.edu/~robotics</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.maa.org/mathland/mathtrek_07_25_05.html</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/~robotics/</span><br /><span 
class="cmtt-10">[crawler]:Parser</span><span 
class="cmtt-10">&#x00A0;find</span><span 
class="cmtt-10">&#x00A0;link:http://www.cs.dartmouth.edu/</span><br /><span 
class="cmtt-10">[Crawler]Crawlinghttp://www.cs.dartmouth.edu/index.php</span><br /><span 
class="cmtt-10">--02:36:11--</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;http://www.cs.dartmouth.edu/index.php</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;=&#x003E;</span><span 
class="cmtt-10">&#x00A0;&#8216;temp&#8217;</span><br /><span 
class="cmtt-10">Resolving</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu...</span><span 
class="cmtt-10">&#x00A0;done.</span><br /><span 
class="cmtt-10">Connecting</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu[129.170.213.101]:80...</span><span 
class="cmtt-10">&#x00A0;connected.</span><br /><span 
class="cmtt-10">HTTP</span><span 
class="cmtt-10">&#x00A0;request</span><span 
class="cmtt-10">&#x00A0;sent,</span><span 
class="cmtt-10">&#x00A0;awaiting</span><span 
class="cmtt-10">&#x00A0;response...</span><span 
class="cmtt-10">&#x00A0;200</span><span 
class="cmtt-10">&#x00A0;OK</span><br /><span 
class="cmtt-10">Length:</span><span 
class="cmtt-10">&#x00A0;7,527</span><span 
class="cmtt-10">&#x00A0;[text/html]</span><br /><br /><span 
class="cmtt-10">100%[============================================&#x003E;]</span><span 
class="cmtt-10">&#x00A0;7,527</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;7.18M/s</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;ETA</span><span 
class="cmtt-10">&#x00A0;00:00</span><br /><br /><span 
class="cmtt-10">02:36:11</span><span 
class="cmtt-10">&#x00A0;(7.18</span><span 
class="cmtt-10">&#x00A0;MB/s)</span><span 
class="cmtt-10">&#x00A0;-</span><span 
class="cmtt-10">&#x00A0;&#8216;temp&#8217;</span><span 
class="cmtt-10">&#x00A0;saved</span><span 
class="cmtt-10">&#x00A0;[7527/7527]</span><br /><br /></div></div>
<!--l. 253--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-7000"></a>What does the TARGET_DIRECTORY look after the crawler has run</h3>
<!--l. 255--><p class="noindent" >For each URL crawled the program creates a file and places in the file the URL and filename. But for a
CRAWLING_DEPTH = 2 as in this example there are a large amount of webpages are crawled and files
created. For example, if we do a look at the files created in the [TARGET_DIRECTORY] pages directory
in this case, then crawler creates 184 files (184 webpages) of 3.2 Megabtes. That means for a depth of 2 on
the departmental webpage there are 184 unique URLs. In fact there might be more - some could be stale
URLs aka deadlinks - something to check for in your crawler. For example, using wget on a deadlink will
return the following:
<div 
class="colorbox" id="colorbox5"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">$</span><span 
class="cmtt-10">&#x00A0;wget</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu/deadlink.html</span><br /><span 
class="cmtt-10">--12:05:41--</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;http://www.cs.dartmouth.edu/deadlink.html</span><br /><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;</span><span 
class="cmtt-10">&#x00A0;=&#x003E;</span><span 
class="cmtt-10">&#x00A0;&#8216;deadlink.html&#8217;</span><br /><span 
class="cmtt-10">Resolving</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu...</span><span 
class="cmtt-10">&#x00A0;done.</span><br /><span 
class="cmtt-10">Connecting</span><span 
class="cmtt-10">&#x00A0;to</span><span 
class="cmtt-10">&#x00A0;www.cs.dartmouth.edu[129.170.213.101]:80...</span><span 
class="cmtt-10">&#x00A0;connected.</span><br /><span 
class="cmtt-10">HTTP</span><span 
class="cmtt-10">&#x00A0;request</span><span 
class="cmtt-10">&#x00A0;sent,</span><span 
class="cmtt-10">&#x00A0;awaiting</span><span 
class="cmtt-10">&#x00A0;response...</span><span 
class="cmtt-10">&#x00A0;404</span><span 
class="cmtt-10">&#x00A0;Not</span><span 
class="cmtt-10">&#x00A0;Found</span><br /><span 
class="cmtt-10">12:05:41</span><span 
class="cmtt-10">&#x00A0;ERROR</span><span 
class="cmtt-10">&#x00A0;404:</span><span 
class="cmtt-10">&#x00A0;Not</span><span 
class="cmtt-10">&#x00A0;Found.</span><br /><br /></div></div>
<!--l. 274--><p class="noindent" >Here are the files from crawling:
<div 
class="colorbox" id="colorbox6"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">[atc@dhcp-212-163</span><span 
class="cmtt-10">&#x00A0;pages]</span><span 
class="cmtt-10">&#x00A0;ls</span><span 
class="cmtt-10">&#x00A0;|</span><span 
class="cmtt-10">&#x00A0;sort</span><span 
class="cmtt-10">&#x00A0;-n</span><br /><span 
class="cmtt-10">1</span><br /><span 
class="cmtt-10">2</span><br /><span 
class="cmtt-10">3</span><br /><span 
class="cmtt-10">4</span><br /><span 
class="cmtt-10">5</span><br /><span 
class="cmtt-10">6</span><br /><span 
class="cmtt-10">7</span><br /><span 
class="cmtt-10">8</span><br /><span 
class="cmtt-10">9</span><br /><span 
class="cmtt-10">=====</span><br /><span 
class="cmtt-10">SNIP</span><br /><span 
class="cmtt-10">=====</span><br /><span 
class="cmtt-10">174</span><br /><span 
class="cmtt-10">175</span><br /><span 
class="cmtt-10">176</span><br /><span 
class="cmtt-10">177</span><br /><span 
class="cmtt-10">178</span><br /><span 
class="cmtt-10">179</span><br /><span 
class="cmtt-10">180</span><br /><span 
class="cmtt-10">181</span><br /><span 
class="cmtt-10">182</span><br /><span 
class="cmtt-10">183</span><br /><span 
class="cmtt-10">184</span><br /><br /></div></div>
<!--l. 310--><p class="noindent" >OK. You are done.
<!--l. 312--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-8000"></a>Looking at the format of the save files</h3>
<!--l. 314--><p class="noindent" >Note, that each webpage is saved as a unique document ID starting at 1 and incrementing by one. Below
we less three files (viz. 1, 5, 139). As you can see the crawler has stored the URL and the current depth
value when the page was crawled.
<div 
class="colorbox" id="colorbox7"><div class="BVerbatimInput"><br /><span 
class="cmtt-10">[atc@dhcp-212-163</span><span 
class="cmtt-10">&#x00A0;pages]</span><span 
class="cmtt-10">&#x00A0;less</span><span 
class="cmtt-10">&#x00A0;1</span><br /><br /><span 
class="cmtt-10">www.cs.dartmouth.edu</span><br /><span 
class="cmtt-10">0</span><br /><span 
class="cmtt-10">&#x003C;!DOCTYPE</span><span 
class="cmtt-10">&#x00A0;html</span><span 
class="cmtt-10">&#x00A0;PUBLIC</span><span 
class="cmtt-10">&#x00A0;"-//W3C//DTD</span><span 
class="cmtt-10">&#x00A0;XHTML</span><span 
class="cmtt-10">&#x00A0;1.0</span><span 
class="cmtt-10">&#x00A0;Strict//EN"</span><span 
class="cmtt-10">&#x00A0;"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&#x003E;</span><br /><span 
class="cmtt-10">&#x003C;html</span><span 
class="cmtt-10">&#x00A0;xmlns="http://www.w3.org/1999/xhtml"</span><span 
class="cmtt-10">&#x00A0;xml:lang="en"</span><span 
class="cmtt-10">&#x00A0;lang="en"&#x003E;</span><br /><br /><span 
class="cmtt-10">====</span><br /><span 
class="cmtt-10">SNIP</span><br /><span 
class="cmtt-10">====</span><br /><br /><span 
class="cmtt-10">atc@dhcp-212-163</span><span 
class="cmtt-10">&#x00A0;pages]</span><span 
class="cmtt-10">&#x00A0;less</span><span 
class="cmtt-10">&#x00A0;5</span><br /><br /><span 
class="cmtt-10">http://www.cs.dartmouth.edu/people.php</span><br /><span 
class="cmtt-10">1</span><br /><span 
class="cmtt-10">&#x003C;!DOCTYPE</span><span 
class="cmtt-10">&#x00A0;html</span><span 
class="cmtt-10">&#x00A0;PUBLIC</span><span 
class="cmtt-10">&#x00A0;"-//W3C//DTD</span><span 
class="cmtt-10">&#x00A0;XHTML</span><span 
class="cmtt-10">&#x00A0;1.0</span><span 
class="cmtt-10">&#x00A0;Strict//EN"</span><span 
class="cmtt-10">&#x00A0;"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&#x003E;</span><br /><span 
class="cmtt-10">&#x003C;html</span><span 
class="cmtt-10">&#x00A0;xmlns="http://www.w3.org/1999/xhtml"</span><span 
class="cmtt-10">&#x00A0;xml:lang="en"</span><span 
class="cmtt-10">&#x00A0;lang="en"&#x003E;</span><br /><br /><br /><span 
class="cmtt-10">====</span><br /><span 
class="cmtt-10">SNIP</span><br /><span 
class="cmtt-10">====</span><br /><br /><span 
class="cmtt-10">[atc@dhcp-212-163</span><span 
class="cmtt-10">&#x00A0;pages]</span><span 
class="cmtt-10">&#x00A0;less</span><span 
class="cmtt-10">&#x00A0;139</span><br /><br /><span 
class="cmtt-10">http://www.cs.dartmouth.edu/ug_honors.php</span><br /><span 
class="cmtt-10">2</span><br /><span 
class="cmtt-10">&#x003C;!DOCTYPE</span><span 
class="cmtt-10">&#x00A0;html</span><span 
class="cmtt-10">&#x00A0;PUBLIC</span><span 
class="cmtt-10">&#x00A0;"-//W3C//DTD</span><span 
class="cmtt-10">&#x00A0;XHTML</span><span 
class="cmtt-10">&#x00A0;1.0</span><span 
class="cmtt-10">&#x00A0;Strict//EN"</span><span 
class="cmtt-10">&#x00A0;"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&#x003E;</span><br /><span 
class="cmtt-10">&#x003C;html</span><span 
class="cmtt-10">&#x00A0;xmlns="http://www.w3.org/1999/xhtml"</span><span 
class="cmtt-10">&#x00A0;xml:lang="en"</span><span 
class="cmtt-10">&#x00A0;lang="en"&#x003E;</span><br /><br /><br /></div></div>
                                                                                  
                                                                                  
<!--l. 358--><p class="noindent" ><span 
class="cmbx-10">Tip</span>: Make sure you always logout when you are done and see the prompt to login again before you leave
the terminal.
 
</body></html> 

                                                                                  


